CPU(i5)でのテスト　

runfile('C:/Users/hkawaguc.ZENYAKU/GitHub/Hello-World/mnist_mlp.py', wdir='C:/Users/hkawaguc.ZENYAKU/GitHub/Hello-World')

Using TensorFlow backend.
60000 train samples
10000 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 512)               401920    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 512)               262656    
_________________________________________________________________
dropout_2 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 10)                5130      
=================================================================
Total params: 669,706
Trainable params: 669,706
Non-trainable params: 0
_________________________________________________________________
Train on 60000 samples, validate on 10000 samples
Epoch 1/20
60000/60000 [==============================] - 12s 203us/step - loss: 0.2473 - acc: 0.9231 - val_loss: 0.1194 - val_acc: 0.9621
Epoch 2/20
60000/60000 [==============================] - 11s 190us/step - loss: 0.1044 - acc: 0.9681 - val_loss: 0.0824 - val_acc: 0.9748
Epoch 3/20
60000/60000 [==============================] - 12s 195us/step - loss: 0.0762 - acc: 0.9764 - val_loss: 0.0678 - val_acc: 0.9798
Epoch 4/20
60000/60000 [==============================] - 12s 199us/step - loss: 0.0607 - acc: 0.9814 - val_loss: 0.0699 - val_acc: 0.9813
Epoch 5/20
60000/60000 [==============================] - 12s 200us/step - loss: 0.0483 - acc: 0.9849 - val_loss: 0.0686 - val_acc: 0.9839
Epoch 6/20
60000/60000 [==============================] - 13s 211us/step - loss: 0.0433 - acc: 0.9873 - val_loss: 0.0702 - val_acc: 0.9827
Epoch 7/20
60000/60000 [==============================] - 13s 217us/step - loss: 0.0394 - acc: 0.9889 - val_loss: 0.0807 - val_acc: 0.9814
Epoch 8/20
60000/60000 [==============================] - 13s 211us/step - loss: 0.0348 - acc: 0.9898 - val_loss: 0.0769 - val_acc: 0.9822
Epoch 9/20
60000/60000 [==============================] - 12s 206us/step - loss: 0.0319 - acc: 0.9910 - val_loss: 0.0766 - val_acc: 0.9841
Epoch 10/20
60000/60000 [==============================] - 11s 190us/step - loss: 0.0277 - acc: 0.9915 - val_loss: 0.0877 - val_acc: 0.9828
Epoch 11/20
60000/60000 [==============================] - 11s 191us/step - loss: 0.0268 - acc: 0.9927 - val_loss: 0.0911 - val_acc: 0.9823
Epoch 12/20
60000/60000 [==============================] - 11s 192us/step - loss: 0.0263 - acc: 0.9926 - val_loss: 0.0966 - val_acc: 0.9826
Epoch 13/20
60000/60000 [==============================] - 12s 199us/step - loss: 0.0233 - acc: 0.9935 - val_loss: 0.0920 - val_acc: 0.9840
Epoch 14/20
60000/60000 [==============================] - 14s 225us/step - loss: 0.0220 - acc: 0.9940 - val_loss: 0.1011 - val_acc: 0.9831
Epoch 15/20
60000/60000 [==============================] - 12s 202us/step - loss: 0.0206 - acc: 0.9942 - val_loss: 0.0996 - val_acc: 0.9819
Epoch 16/20
60000/60000 [==============================] - 12s 200us/step - loss: 0.0207 - acc: 0.9947 - val_loss: 0.1002 - val_acc: 0.9834
Epoch 17/20
60000/60000 [==============================] - 12s 197us/step - loss: 0.0184 - acc: 0.9952 - val_loss: 0.0978 - val_acc: 0.9833
Epoch 18/20
60000/60000 [==============================] - 11s 184us/step - loss: 0.0198 - acc: 0.9949 - val_loss: 0.1133 - val_acc: 0.9817
Epoch 19/20
60000/60000 [==============================] - 12s 194us/step - loss: 0.0184 - acc: 0.9955 - val_loss: 0.1108 - val_acc: 0.9828
Epoch 20/20
60000/60000 [==============================] - 11s 192us/step - loss: 0.0179 - acc: 0.9954 - val_loss: 0.1048 - val_acc: 0.9835
Test loss: 0.10476597903530414
Test accuracy: 0.9835
