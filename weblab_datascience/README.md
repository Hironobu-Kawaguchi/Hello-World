GCI
=======

# 受講を始める前に

本講座ではjupyter notebookを使うので、事前に環境のセットアップをしてください。
Anaconda( https://www.anaconda.com/ )やiLect( http://ilect.net/ )の使用をおすすめします。なお、Anacondaをご使用の場合、ご自身でデータベースをセットアップする必要があります。


1 データサイエンティスト講座概要とPythonの基礎

2 Numpy、Scipy、Pandas、Matplotlibの基礎

3 記述統計学と単回帰分析

4 確率と統計の基礎

5 Pythonによる科学計算の基礎（NumpyとScipy）

6 Pandasを使ったデータ加工処理

7 Matplotlibを使ったデータ可視化

8 データベースとSQLの基礎

9 データベースの応用（高度なSQL処理と高速化）、データベースとSQLの基礎 (Python)

10 ドキュメント型DB（MongoDB）

11 機械学習の基礎（教師あり学習）

12 機械学習の基礎（教師なし学習）

13 モデルの検証方法とチューニング方法

14 データサイエンティスト中級者への道

15 総合演習問題


この講座のコンテンツは次のようになります。第1章がこのJupyterNoteBookの使い方とPythonの基礎、2章がNumpy・Scipy・Pandas・Matplotlibの基礎で、データハンドリングに使うライブラリと基本的なテクニックをここで学びます。これらのライブラリのさらなる活用方法については、後の章で学びます。3章が実際のデータを使った記述統計学と回帰分析で、2章で学んだNumpyやPandas等を使っていきます。4章が確率統計の基礎になり、少し理論的なお話になり数式も出てきますが、徐々に慣れていきましょう。

5章が科学計算に使われるNumpyやScipy、6章でデータ加工処理に必要となるPandasを使ったテクニック、7章がデータの可視化(Matplotlib)について学びます。この章までにPythonのデータ分析前の処理や加工の基礎を身につけていただき、総合問題でそれらの手法を活用します。具体的には金融の時系列データやマーケティングデータをハンドリングをして、データ分析の実務現場でも使われている基礎的な手法を紹介します。

8章からはデータベースの話になり、データベースとSQLの基礎スキルを身につけます。9章でSQLの応用的な処理、10章ではMongoDBのNoSQLについて学びます。データはDBにあるケースもありますし、テキスト形式等で保存されているケースもありますので、ここで学ぶデータ加工処理を学べば、後の工程が楽になります。また、DBはPythonとも連携が可能で、その接続方法などについても紹介します。

11章からは、機械学習の単元になります。はじめは教師あり学習、次の12章で教師なし学習、そして13章がその機械学習で学んだモデリングの検証やチューニング方法になります。モデルは作ったら終わりではなく、検証をしっかりとする必要があり、オーバーフィッティング等についても述べます。

最後は今後の学習として、14章でデータサイエンスの中級者になるために必要なスキル、例えばPythonの高速化や深層学習入門、Spark(Pyspark)を紹介します。この教材はデータサイエンスの入り口ですので、大事なのはこれからの学習をさらに広げて、深めていくことです。そのために、これらのコンテンツを作成しました。まとめとして、15章は総合問題となります。

この講座をすべて完了すれば、データ分析に必要な最低限のスキルと、今注目されている深層学習などを学ぶための前知識も身につけることができます。余談ですが、ここでデータ分析のスキルをしっかりと身につければ、自分の市場価値を上げることができますし、就職や転職するときに選択肢が大きく広がります。
